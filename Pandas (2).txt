pd.read_csv: parse_dates much faster than converters np.datetime; slightly faster with date_parser=ciso8601.parse_datetime

s.to_frame(name="x")

columns type behaves like set (operations)
df[[c1,c2]]
groupby object describe()
with pd.option_context("max_rows",20):
after plot:
as=df.plot()
ax.yaxis.get_label()
df.filter(regex=..) # filter columns
s.dtype.kind=="O"

General
=======
* use library ``numexpr`` and ``bottleneck`` for performance of some binary and comparison operations [see recommended dependencies]

Series
======
* Initialization
  * ``Series(data, index=index)``
  * data is dict, ndarray or scalar (will be repeated; needs index)
  * without an index, a counting index is created
  * non-unique index possible (but will raise exception on some operations)
* is dict-like
* operations with multiple series automatically align index
* have optional ``.name`` attribute
* methods:
  * ``nunique()`` number of unique values
  * ``.value_counts()`` (also as top-level function)
  * ``.map(func)`` takes single values (``func`` can be dict to translate values)
  * use ``s.str.<...>`` methods for string methods (e.g. ``s.str.upper()``) which exclude NaNs
  * ``s.isin(list)`` return boolean if series element in enumeration
  * ``.dtype``
  * ```s.where(boolarr)`` preserve shape; return series but with NaN where criterion false (instead of shrinking)

DataFrame
=========
* Initializationhave indices and column labels
  * ``DataFrame(data, index=..., columns=...)``
  * dict of 1D (columns will be sorted keys unless provided)
  * list of dicts
  * 2D ndarray; MaskedArray for missing values
  * structured ndarray
  * Series
  * DataFrame
  * can use tuples dict to create multi-index frame
  * alternatively:
    * ``DataFrame.from_dict``
    * ``DataFrame.from_records``
    * ``DataFrame.from_items``
* if index passed and data is dict, dict keys not in index will be dropped
* attributes:
  * ``.index``, ``.columns`` (can be assigned to)
  * ``.shape``
  * ``.values`` to get data as np.array
  * ``.dtypes``
* Methods:
  * ``df.T`` transpose
  * ``df.dot()`` dot-product
  * ``df.info()`` for summary
  * ``df.to_string()`` for text table (use global ``set_option('line_width', width)``)
  * ``df.head()``, ``df.tail()``
  * ``.empty`` test if empty
  * ``.any()``, ``.all()`` to summary a boolean result
  * ``.bool()`` to evaluate single element as bool
  * ``.copy()``
  * ``.get_dtype_counts()``: counts for each dtype
* binary broadcast operations:
  * ``.add``, ``.sub``, ``.mul``, ``.div``
  * use ``axis`` keyword for orientation
  * ``fill_value=`` parameter for missing values
  * ``df.equals(df2)`` to test with NaNs being true
  * ``df.combine_first(df2)`` to insert missing values of first with data from second
  * more general ``df.combine(df2, combiner_func)``
  * ``.df.astype([copy=True])``
  * ``.convert_objects([convert_numeric=False])`` convert object-type to lower type (convert_numeric tries strings to number)
* Aggregation:
  * ``.sum()``, ``.mean()``, ``.quantile()``, ``.count()``, ``mad()``, ``.median()``
  * ``.max()``, ``.min()``, ``.mode()``, ``.abs()``, ``.prod()``, ``.std()``, ``.var()``, ``.skew()`` (3rd moment), ``.kurt()`` (4th moment), ``.()``
  * ``.cumsum()``, ``.cumprod()``, ``.cummax()``, ``.cummin()``
  * ``axis=`` (``"index"``, ``0`` [default] or ``"columns"``, ``1``)
  * ``skipna=`` parameter
  * e.g. ``(df-df.mean())/df.std()`` or ``df.sub(df.mean(1), axis=0).div(df.std(1), axis=0)``
* Reading
  * ``df["col"]``, ``df.col`` (works with IPython auto-complete)
  * ``df.loc["label"]``
  * ``df.iloc[labelindex]``
  * ``df[<slice>]`` returns dataframe
  * ``df[boolvec]``  returns dataframe
  * default iteration (and iteritems) over columns
  * ``df.iterrows()`` gives srow index, values (does not preserve dtype across rows)
  * ``df.itertuples()`` yield row tuples (first element is index)
  * ``df.isin(list)``  boolean if df value in sequence
  * ``df.isin(dict)`` boolean if cols (dict keys) have correct values (dict values); cols not in keys will be all false
  * ``df.where(boolarr[, other=<defaultvalue>, inplace=False])`` preserve shape; yield NaN where criterion false; defaultvalue can also be mapping like a dataframe
    * ``axis=``, ``level=``
* writing:
  * ``df[col]=data`` (scalar values repeated, columns inserted at end unless ``df.insert(pos, name, data)``)
  * ``delete df[col]``
  * ``df.pop(col)``
  * ``.apply(func [, axis=...])``; result lower dim or the same (vectorized version)
  * ``.applymap(func)`` takes arbitrary Python functions and calculates on single values
* information:
  * ``df.value_range()``
  * ``df.sort_index([axis=0] [, ascending=True] [, by="col"])``: ``by=`` also takes list of cols; for multi-index sorting specify all levels
  * ``df.order([na_position="first"])`` treats NaNs, sort by value
  * ``df.sort(...)`` sorts in-place; provided for compatibility with Numpy methods
  * can assign to data frame slice and even reorder (e.g. ``df[["B","A"]]=df[["A","B"]]``)
* for operations with series: series index aligned on dataframe columns (broadcasting; unless TimeSeries!)

All
===
* ``d.describe()`` some information (even categorical data)
* ``d.idxmin()``, ``d.idxmax()`` (for dataframe might need ``axis=``); will return first match if multiple
* ``cut(arr, ...)``, ``qcut(arr, ...)`` [quantiles] to discretize (also takes ``np.inf``); will return intervals
* default types ``int64`` and ``float64`` (regardless of platform; unlike numpy)
* use ``pd.options`` to set some behaviour and display style
* ``pd.core.common.set_eng_float_format()`` to alter float formatting
* ``.mask(criterion)`` is inverse of ``.where()``

Reindexing
==========
* ``reindex``: reorder data, create new missing values, fill missing data (e.g. for timeseries)
* ``s.reindex([...])``: reorder (and possibly drop some indices)
* ``df.reindex(index=[...], columns=[...])``; ``df.reindex_axis([...], axis=...)``
* indices can be shared (e.g. ``df.reindex(df2)``)
* many operations faster with pre-aligned data!
* ``df.reindex_like(df2)``
* ``df.align(df2, join=... [, axis=...])`` inner, left, right, outer
* ``method=``: ``ffill``, ``bfill``; index needs to be monotonic; could also use ```.fillna()``
* ``.drop([...] [,axis=...])`` drop rows
* ``df.rename()`` rename index based on function or mapping; ``inplace=True`` to avoid copy

Selecting and Indexing
======================
* ``.loc`` label based (single, list, slice [end value also included], boolean array)
* ``.iloc`` label position based (number, number array, slice)
* ``.ix`` mixed label [default if no error] and position based
* can also use cols as second arg ``...[rows, cols]`` (cols is slice, dataframe, ...)
* ``df[...]``
  * slices will slice rows
  * criterion/boolarr element will be aligned with data so that setting is possible (e.g. ``df[df[1:3]>0]=1``)
* also possible as attribute
* can also assign to slices
* v0.14 has out-of-bound default value(?)
* can also assign to and thus enlarge dataframe
* for performance single value access use ``df.at[...,...]`` or ``df.iat[...,...]``
* use ``df.map(func)`` for more complex boolean indexing
* ``df.query(expr)``
  * can use ``and`` instead of ``&``; comparisons tighter than operators (don't need parenthesis)
  * e.g. ``df.query('(a < b) & (b < c)')`` (instead of ``df[(df.a < df.b) & (df.b < df.c)]``)
  * use ``index`` (or ``ilevel_0``) pseudovariable or ``df.index.name="..."`` before if you want to use index
  * can also use level(names) of a multiindex as variable (or use special names ``ilevel_0`` etc)
  * supports ``in`` and ``not in`` to query if in another cols at all
  * ``numexpr`` used whereever possible (slightly faster than conventional for more than 200,000 rows)
  * ``var == [...]`` same as ``in``` (and similar for ``!=``)
  * negate boolean with ``not`` or ``~``
* ``.take(arr)``:
  * arr is sequence of integer positions (negative if end of data)
  * for dataframe ``axis=``
  * not for boolean selection
  * slightly faster than indexing
* duplicates:
  * ``df.duplicated(cols)``: boolean if value duplicated
  * ``df.drop_duplicates(cols)``
  * uses first occurence unless ``take_last=True``
* ``df.select(func [,axis=0])``: func tests labels
* ``df.lookup(labels, cols)`` look up multipl values and return numpy array
* ``Float64Index`` used so that label-based slicing possible; only ``.iloc`` will be positional!; float slices allowed
* Index objects:
  * ``index=Index([...] [, name="..."])``
  * methods ``union``, ``intersection``, ``diff``, ``sym_diff`` (and also the overloaded operators)
  * ``isin`` method
  
Multiindex
==========
* like array of unique tuples
* ``MultiIndex.from_tuples([(a,b), (c,d), ...])``
* ``MultiIndex.from_arrays()``
* ``MultiIndex.from_product([a,b,c],[d,e])``
* parameter ``names=[...]``
* in dataframe ``index=[arr1, arr2, ...]`` will create multiindex
* could you tuples as index, but multiindex allowed grouping etc.
* ``pd.set_option('display.multi_sparse', True)``
* ``index.get_level_values(...)`` to get labels at each location
* ``.loc[lev1, lev2, ...]`` will remove these levels
* can also slice with a range of tuple values
* can pass a list of labels/tuples
* 0.14:
  * provide multiple indexers
  * specify all levels fir ``.loc`` (otherwise ambigious)
  * selection axis needs to be sorted (``.sortlevel([axis=0])``)
  * slice(None) for all of that level
  * use ``idx=pd.IndexSlice`` for nicer notation with ``:`` in list
  * ``df.loc(axis=0)[...]``
  * can also assign to; even any alignable object (e.g. other dataframe)
  * ``df.xs(label, level="...")``, ``axis=``; can select on multiple keys with tuple as level; ``drop_level=False`` to preserve shape
* methods like ``.reindex()``, ``.align()``, ``.mean()`` take ``level=`` parameter
* checks sort depth
* ``.swaplevel(...,...)``, ``.reorder_levels([...])``
* attributes ``.levels``, ``.labels``, ``.names``; sorting only determined by interger labels
* indexes immutable but can change meta-data (``.names``); or use ``.rename``, ``.set_names``, ``.set_levels``, ``.set_labels``; can do ``inplace=True``
* ``df.set_index()`` to set a column as the index; ``append=True`` to add to previous indices; ``drop=False`` to not drop column from data; ``inplace=`` 
* ``.reset_index()`` move index to columns; ``level=``; ``drop=`` to simply remove
* add index: ``df.index=index``

GroupBy
=======
* creates GroupBy object which is mapping to group names
* ``df.groupby(...)``:
  * function on label
  * sequence of same length
  * dict or Series as mapping
  * string for column name
  * list of any of the above
  * ``sort=False`` for some speed-ups
  * ``level=``
  * ``as_index=``
* attributes:
  * ``groups``, ``.labels`` (axis labels)
* methods:
  * ``len()`` number of groups
  * ``grouped[...]`` column selection
  * ``for name, group in grouped``
  * ``.agg(func)`` (or ``.aggregate()``); can also:
    * pass list of funcs (or dict to name result columns)
    * func names can be some special strings (e.g. ``"sum"`` -> generates function wrapper; see dispatching)
  * ``.size()`` size of groups
  * ``.transform(func)`` same size as object being grouped
  * ``.count()``, ``.tail()``, ``.head()``, ``.nth()`` (n-th row, ``dropna="any"/"all"`` )
  * ``grouped("col").filter(func)`` filter out groups; ``dropna=False`` to fill with NaN
  * ``.apply()`` most general (can even "describe" here); note that currently dangerous if side-effects in function
  * NaNs in grouping key discarded
  * ``pd.Grouper()`` for more control of grouping
  * ``.cumcount()`` to enumerate groups; ``ascending=True``
  
Concat
======
* pd.concat can join an axis while performing set logic on the other axes (outer, inner, or specific index)
* http://pandas-docs.github.io/pandas-docs-travis/merging.html#concatenating-objects
* can concat dataframes or series
* pass dict to use keys as ``keys=`` argument
* ``.append`` shortcut (along axis 0)
  * ``ignore_index=True`` if all indices should be considered distinct (since are meaningless counting)
  
Join
====
* fairly fast
* ``merge(left, right)``
  * ``how="left"|"right"|"outer"|"inner"``
  * ``on=None`` column names to join on
  * ``left_on=None``, ``right_on=None`` col names to be used as keys
  * ``left_index=False``, ``right_index=False`` use index as join key
  * ``sort=True`` False can improve performance
  * ``suffixes=("_x","_y")`` for name clashes
  * ``copy=True``
* http://pandas-docs.github.io/pandas-docs-travis/merging.html#database-style-dataframe-joining-merging
* DataFrame.join joins on indices by default
* ``ordered_merge`` to combine timeseries and ordered data
* ``df.combine_first(df2)`` take values only if missing
* ``df.update(df2)`` updates non-NA values inplace
* joining on two multiindices not implemented yet, but can be simulated

Missing values
==============
* ``float("nan")`` used

* pd.util.test.rands for random string

Cookbook
========
Reorder columns
df=df.reindex(columns=..., index=...)

Pitfalls
========
* `groupby` excludes NaN-like values (also None)