== Clustering

* Subspace clustering: cluster may exist only on subspace
* OPTICS: easier hyperparameters than DBSCAN, in sklearn (v0.21)
* unsupervised metric: http://scikit-learn.org/dev/modules/generated/sklearn.metrics.davies_bouldin_score.html[Davies Bouldin Score]

=== Normalized cuts

* good, but slow (?)
* "Normalized cuts and image segmentation" (Shi, Malik)

=== Mean shift - Feature space clustering

* "Mean shift analysis and applications" (Comaniciu)
* "Mean Shift: A Robust Approach Toward Feature Space Analysis" (Comaniciu)
* smooth data, but preserve boundaries between regions
* dilate points as hypersphere

=== Felsenszwalb

* http://people.cs.uchicago.edu/~pff/papers/seg-ijcv.pdf["Efficient graph-based image segmentation"] (Felsenszwalb)
* fast (NlogN in pixels)
* segmenation adaptively adjusts to regions of image
* however, will leak segments if boundary has a weakest link
* method compares:
** intensity difference across boundary - minimum link
** intensity difference inside region plus interior extra score - largest of minimal spanning tree
** interior extra score: value of region plus (scale-factor / region-size)
* algorithm is guaranteed to
** not do a split too many (regions with no evidence of boundary)
** not do a split too few (splittable region)
* 8 neighbor graph; weights are absolute intensity differences
* for color images: do separately per RGB channel and use intersection of these 3 clusterings (same cluster in all channels)
* adjustments:
** use quantile and not minimum of difference across boundary, but this makes it NP hard
** interior extra score could be shape dependent (e.g. ratio of area to perimeter)
** do graph in (x,y,r,g,b) feature space -> e.g. better if color important, e.g. image of flowers

=== Cycles in graph embedded image plane

* "Globally optimal regions and boundaries as minimum ratio weight cycles" (Jerman, Ishikawa)
* was mentioned, but not clear if it works