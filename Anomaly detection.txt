= Anomaly detection

== Libraries

* https://github.com/nicolasmiller/pyculiarity[pyculiarity]: Twitter Anomaly Detection (port of R package); needs R
** https://github.com/twitter/AnomalyDetection[Twitter Anomaly Detection]: original R version
** https://github.com/Marcnuth/AnomalyDetection[Marcnuth]: alternative without R
* https://hdbscan.readthedocs.io/en/latest/outlier_detection.html[HDBSCAN Outlier]
* http://scikit-learn.org/stable/modules/outlier_detection.html[Scikit-learn]: One-Class-SVM, Isolation Forest, Local Outlier Factor, Elliptic envelope
* https://github.com/yzhao062/Pyod[PyOD]
* http://docs.h2o.ai/h2o/latest-stable/h2o-r/docs/reference/h2o.anomaly.html[H2O]
* http://nupic.docs.numenta.org/1.0.0/api/algorithms/anomaly-detection.html[NuPIC]
* https://elki-project.github.io/algorithms/[ELKI]
* https://github.com/linkedin/luminol[Luminol (Linkedin)]
* https://github.com/tsurubee/banpei[Banpei]
* https://github.com/netflix/surus[Surus (Netflix)]: Robust PCA in Hive, Pig
* https://github.com/khundman/telemanom[Telemanom (NASA)]: LSTM
* https://github.com/smirmik/CAD[CAD]: Contextual Anomaly Detector; winner of a NAB competition
* https://github.com/STREAM3/pyISC[PyISC]
* https://github.com/seninp/saxpy[SaxPy]

* https://github.com/MentatInnovations/datastream.io[datastream.io]
* https://github.com/nlittlepoole/thermometr[Thermometr]: Twitter S-H-ESD algorithm
* https://pypi.org/project/kenchi/[kenchi]
* http://www.cit.mak.ac.ug/staff/jquinn/software/lsanomaly.html[LSAnomaly]
* https://github.com/etsy/skyline[Skyline]
** https://github.com/earthgecko/skyline[Skyline (Earthgecko)]: some improvements
* https://github.com/yahoo/egads[EGADS (Yahoo)]: Java
* https://github.com/GYXie/anomaly-detection[GYXie]
* https://github.com/eleme/banshee[Banshee]
* https://github.com/nathanielc/morgoth[Morgoth]
* https://github.com/lytics/anomalyzer[Anomalyzer]
* https://github.com/haowen-xu/donut[Dobut]: seasonal KPIs
* https://github.com/keiraqz/anomaly-detection[Anomaly detection (Keiraqz)]: on Spark
* https://github.com/adiyoss/DeepAnomaly[DeepAnomaly]: neural network, 2016
* https://github.com/dmbee/seglearn[Seglearn]
* https://github.com/christophmark/bayesloop[BayesLoop]
* https://github.com/sk1010k/SmartSifter[SmartSifter]
* https://stats.stackexchange.com/questions/137094/algorithms-for-time-series-anomaly-detection

* https://github.com/baidu/Curve[Curve (Baidu)]: Labeling helper
* https://github.com/Microsoft/TagAnomaly[TagAnomaly (Microsoft)]: Labeling helper

=== Prediction

* https://github.com/facebook/prophet[Prophet (Facebook)]
* https://github.com/RJT1990/pyflux[PyFlux]
* https://github.com/tgsmith61591/pyramid[Pyramid]
* https://github.com/rtavenar/tslearn[tslearn]
* https://github.com/jakobrunge/tigramite[Tigramite]

== Resources

* https://github.com/yzhao062/anomaly-detection-resources[Y Zhao]
* https://github.com/hoya012/awesome-anomaly-detection[Hoya]: mainly research papers
* http://dsmi-lab-ntust.github.io/AnomalyDetectionToolbox/: See Comparison
* https://github.com/rob-med/awesome-TS-anomaly-detection[Rob Med]
* http://web.stanford.edu/class/cs259d/[Stanford Cybersecurity course]

== Websites

* http://www.early-warning-signals.org/

== Papers

* http://www.hamilton.ie/florian/infocom2008.pdf[Adaptive Kalman filter]

== Mentions

* AutoEncoders
* RNN, LSTM
* Subsequence clustering?

== Other

* https://github.com/albertcthomas/anomaly_tuning: Parameter tuning notebook
* https://github.com/fastforwardlabs/anomaly_detection/blob/master/Anomaly%20Detection%20Post.ipynb[Fast forward labs]: Probabilistic programming notebook
* http://www.cs.cmu.edu/~./awm/tutorials/biosurv01.pdf[Bio Surv Slides]

== Review Pimentel

* "A review of nevlty detection" (Pimentel, Clifton, Tarassenko; 2014)
* Subspaces could be important in high dimensions
* Categories:
** probabilistic: fit probability distribution and set threshold
*** parametric: GMM; non-parametric: kernel-density estimation
*** functional form may not be good fit
*** need many samples
*** threshold has no probabilistic interpretation since only probability density
*** SmartSifter: Ref 117; https://github.com/sk1010k/SmartSifter[Python], hierarchical structure, discount past
*** ICA-based: Ref 54, Ref 122
*** fuzzy k-nearest clustering + GMM: Ref 48, Ref 49
*** hidden state models: HMM, Kalman filter
** distance-based: nearest neighbors
*** outlier if far
*** HighDOD for outlier subspaces: Ref 171
*** Local Outlier Factor; alsosome variations
*** cluster-based: find clusters and distances from prototypes
*** need distance metric
*** work incrementally
** reconstruction-based: predict what would be normal
*** many ideas with neural networks
** domain-based: fit hard boundary
*** one-class SVMs; many variations
** information-theoretic: score groups by some IC
*** doesnt seem that great
* has multiple reference for outliers on categorical data
* try PCA, Kernel PCA (maybe better with L1 norm); maybe CCA; Robust PCA

== Tests

* https://en.wikipedia.org/wiki/Grubbs%27_test_for_outliers[Grubbs test]: assume normality; detects outlier iteratively

== Examples

=== LSTM by Uber

* https://eng.uber.com/neural-networks/
* feature extraction was key (strength of curvature, spikiness, ...)