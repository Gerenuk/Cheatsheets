= Toolz Quickref

:toc:

== Basic functions

[cols="m,d"]
|===
| *curry*(func)                             | can write f=func(a);f(b)
| *from* toolz.curried import *             | import all functions in curried form
| *pipe*(data, func1, func2...)             | but use curried functions
| *accessors*                               | get, pluck                  |
| *valmap*                                  | for groupby results            |
| *groupby*                                 | not streaming!                |
| *reduceby*                                | for streaming split-apply-combine         |
| *reduceby*(group_select_func, reduce_aggregator, data) |
| *join*(key_func_A, data_A, key_func_B, data_B) | returns (ai, bi) tuples; RHS is streamed, LHS in memory
|===

toolz developed against multiprocessing and IPython.parallel 
(for serialization pickle; or "dill" if it fails) |

toolz has no parallel processing, but uses algorithms that work with existing parallel systems -> need user given map function
e.g. toolz.sandbox.parallel.fold works with multiprocessing.Pool.map, threading.Pool.map, IPython.parallel.map_async |

== Notable functions

[cols="m,d"]
|===
| *groupby*                                 | global grouping
| *merge_sorted*                            |
| *interleave*                              |
| *isdistinct*                              |
| *concat*(seqs)                            | like chain.from_iterable
| *mapcat*(func_on_list, list_of_lists)     |
| *cons*                                    | prepend
| *interpose*(sep, seq)                     | put sep between elements of seq
| *frequencies*(seq)                        | count
| *reduceby*                                | groupby and reduction
| *iterate*(func, start)                    | repeatedly apply func on start
| *sliding_window*(n, seq)                  | overlapping sequences
| *partition*(n, seq, pad)                  | final dropped unless pad
| *partition_all*(n, seq)                   | partition but keep partial at the end
| *pluck*(ind, seqs, default=..)            | map(curried.*get*(ind), seqs); index single or multiple
| *join*                                    |
| *diff*(*seqs, ..)                         | return elements that differ
| *topk*(k, seq, key=None)                  | find top k elements
| *countby*(key, seq)                       | count, but by result of key(el)
| *partition_by*(func, seq)                 | partition where blocks of the result have func=True or func=False
| *identity*                                |
| *thread_first*(val, *funcs)               | apply funcs; use tuple if funcs need parameters; previous value is put in first place when multiple arguments
| *thread_last*(..)                         |
| *memoize*(func)                           | cache function result; can also use as decorator; use cache kwarg for initial cache
| *compose*(f1, f2, ..)                     |
| *pipe*(data, f1, f2, ..)                  |
| *f*2=complement(f1)                       | invert boolean value of function
| *juxt*(f1, f2)(x)                         | applies several functions to same x and returns tuple;
| *juxt*([f1, f2])(x)                       |
| *do*(f, x)                                | apply f(x) but still return x; e.g. for logging
| *curry*                                   |
| *merge*(*dicts)                           | merge dicts (later has precedence)
| *merge_with*(func, *dicts)                | merge by same key and apply func on multiple values
| *valmap*(func, d)                         | apply to values of dict
| *keymap*(func, d)                         | apply to keys of dict
| *itemmap*                                 |
| *valfilter*(f, d)                         | filter by dict values
| *keyfilter*(f, d)                         |
| *itemfilter*(f, d)                        |
| *assoc*(d, key, val)                      | return new dict with new key=value
| *dissoc*(d, key)                          | return new dict with key removed
| *update_in*(d, keys, func, def=None)      | return new dict with d[k1][k2]..=func(old_val); use default if not found
| *get_in*(keys, nested_dict, default=.., no_default=..) | no_default=True if to raise KeyError or IndexError
| *EqualityHashKey*(key, item)              | enable hashing for unhashable
| *parallel_fold*                           | reduce without ordered reduction
|===

== Itertools

[cols="m,d"]
|===
| count(start, step)                        |
| cycle()                                   |
| repeat(elem, max_n)                       |
| compress("ABC", [1,0,1])                  | "AC"
| tee(it, n)                                | Split
| zip_longest(p,q,...)                      |
| starmap(pow, [(2,5),..])                  |
|===

Other methods are:

* chain, groupby
* dropwhile, filterfalse, takewhile
* product, permutations, ...
 
== Other libraries

* funcy: recent changes
* fn.py:
  * `_ * 2` syntax
  * 2 years ago
  * persistent data structures (preserves previous version even when modified; e.g. SkewHeap)
  * trampoline decorator for tail-call hack
  * functional style error handling with monad.Option
* more_itertools: https://pythonhosted.org/more-itertools/api.html; 3 years ago

= Other

* https://github.com/EntilZha/ScalaFunctional: very recent
* http://fntools.readthedocs.org/en/master/api.html: recent
* http://pydash.readthedocs.org/en/latest/: function chained syntax; based on JS Lo-Dash
