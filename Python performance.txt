= Python performance

== File reading and writing

* Reading: pickle 1, hdf 1, feather 3
* Writing: pickle 0.8, hdf 1, feather 1
* csv.DictReader needs 2x time of csv.reader (with integer indexing)
* maybe try HDF5 for Python or PyTables
* numpy.loadtext very slow
* numpy.fromfile and numpy.load very fast
* pandas.io.parsers.read_csv pretty fast
* only little performance difference between csv.writerow() and csv.writerows() (3% faster)

Pandas HDF very fast (see Pandas doc; much fast than SQL)

== Counting condition

* fast: sum(1 for x in xs if <cond>)
* faster than: sum(<cond> for x in xs))
* fastest: len([1 for x in xs if ...] but needs memory

== Attribute access by name on sequence

* list(pluck("a", l))           : 1x    << use this if >=20 elements
* list(map(itemgetter("a"), l)) : 1.6x
* [x["a"] for x in l]           : 1.6x

== Attribute access by name

* tuple index access 1x
* list index access 1x
* namedtuple index access 1x
* namedtuple name access 2x
* dict name access 1x (but 4x memory size)
* class name access 1.5x

== Math

* `x * x` much faster than `x ** 2`

== Fast hashes

* SHA1, MD5; xxhash

== Sorting

* sorted(.., key=itemgetter(0)) faster than sorted(..)
* a[b.argsort()] even 6x faster
* for reverse use b.argsort()[::-1]

== Min/max on few values

* `x=min(a,b)` # 217ns
* faster: `x=a if a<b else b` # 65ns

== Performance modules

* comparison on http://nbviewer.jupyter.org/github/rasbt/One-Python-benchmark-per-day/blob/master/ipython_nbs/day7_2_jit_numpy.ipynb#Results
** Parakeet-JIT fastest, Numexpr-Evaluate almost as fast
** Cython-Unrolled, Numba-Vectorized second
** Numba-JIT not much better than regular Numpy

== Numexpr

* operations on arrays
* multithreaded
* Intel VML/MKL
* can be better than Numpy since cache-optimized (no intermediate data)
* only integer, float, complex, bytes
* functions:
  * many mathematical
  * where(cond, valtrue, valotherwise)
  * contains(str, substr)
  * reductions: sum/prob/min/max (num, axis)

== Named tuple

* namedtuple type creation pretty slow
* attribute access slower than tuple access
* with pre-created type, named tuple creation "only" 3x slower than dict creation

== Joblib

* knows about numpy arrays

== Others

* Psycho
* Pyrex

== Various results

* plain tuple creation 14x faster than dict creation
* Custom month advancer 30x faster than +relativedelta(months=1)
* avoid string + (since copy); better "join"
* built-in functions faster (e.g. operator.add faster than lambda)
* collections.deque() better for pop/insert(0) operations [no rebuild of full list]
* prefer map() over loop
* avoid member references with . in loops (preevaluate label into variable)
* prefer local variables in loops (write function random=self.random)
* exceptions can be faster than "if key in dict"
* function call overhead high -> rather pass list and do aggregation in function
* avoid "if" if you can split a loop into two parts instead
* "a in b" much faster if b is dict or set
* list comprehension bit faster than for loop
* "while 1:" will be optimized (but not "while True:")
* "x=a;y=b" faster than "x,y=a,b" (only "a,b=b,a" is worth it)
* "x<y<z" faster than "x<y and y<z"
* hacks: "not not x" faster than "bool(x)"
* Profile: distinguish time for pure Python and C Code
* for XML: SAX faster than DOM
* now string concatenation with a=a+"..." is sometimes optimized
* exceptions slow
* `dict()` 6x slower than {}
* often more optimal to replace global lookups with local arguments with default values

== Method for performance

https://www.youtube.com/watch?v=5js_-pLGqwA
* Parakeet, Pyston, Pythran, Intel Distribution for Python, Pybind11, Numba, Swig, Shedskin, Pyjion, CFFI, Boost, Cython, PyPy
* only little code change (up to 8x faster): Cython, PyPy, Shedskin, Pyston
* Cython:
** generates and compiles C code
** without code change not much faster though
** with *notable* annotation ("black art") -> 62x faster; may be less maintainable
* PyPy (recommended):
** 7x faster
** Python 2.7, 3.5
** not done yet: Flask, Pillow, ...
* Shedskin (obsolete):
** automatic type inference, compiles to C
** only Python 2.7
* Pyston (obsolete):
** LLVM JIT
** Dropbox
** Python 2.7 only
** Suspended Jan 2017
* Numba:
** only little annotation needed
** Python 3.4+
** Numpy 1.7-1.11
** JIT
* Parakeet (unactive?):
** JIT
** Subset Python 2.7 only
** only little annotation needed
** Numpy
** little activity in last 4 years
* Pythran
** annotate function in comment
** generate C++ code
** Numpy, Python 2.7 / 3(beta)
** for scientific computating
** subset of Python
* 100x speed if writing in different language (ctypes, C++, CodePy/Boost, CFFI, SWIG, pycxx, Pybing, Rust, Fortran, Go, ...)
* C++ extensions
** C Extension -> much to much to write (mix with C++, precise control; have to write *a lot* of code, manual memory management, testing hard, debugging hard)
** CFFI -> seems good (write in Python, call C from Python, C++ possible, less boilerplate, notable less code than C extension)
** PyBind11 -> need to know more C++ (header only C++ library, write in C++, similar to Boost.Python, C++11; more to write than CFFI, much less than C Ext;)
* !geometric average between tests -> so that ratios between test sets are clear
* benchmarking hard (see video for ideas)

== Libraries

* pseudo-inverse: PyTorch slower
* Eigh: best is JIT-compiled Eigh (SVD for PCA is slow)
* solve lin equation:
** Torch GELS unstable (do `theta_hat[np.isnan(theta_hat) | np.isinf(theta_hat)] = 0`) at end
** regularized Cholesky fastest

== Others

* dict keys look-up slightly faster if keys str.intern
<<<<<<< HEAD


== Profiler

=== Mozilla Functiontrace

    > cargo install functiontrace-server
    > pip install functiontrace
    > /home/anton/.cargo/bin/functiontrace script.py
    
    wait a bit and load json to https://profiler.firefox.com
    
=== vprof

https://github.com/nvdv/vprof
=======
* slotted class smaller than namedtuple (for inline e.g. `Point = type('Point', (), {'__slots__': ('x', 'y'), '__init__': init})`)
* iterating list slightly faster than tuples
* iterating generators faster than lists
* list comprehension slower than map/filter (?)

== Regex

* `.compile` faster
* making lower yourself instead if IGNORE case faster
* own loop usually slower
>>>>>>> e483949a526c922669cbbc8b219ac3f6cd03ed30
